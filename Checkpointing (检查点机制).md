### Checkpointing (检查点机制)

在所有专业的机器学习项目中，我们都会使用一种叫做 **"Checkpointing" (检查点)** 的技术。

Checkpointing 的工作原理如下：

1.  **自动保存**：
    在训练脚本运行时（通常是在**每一轮 epoch 结束时**），脚本会自动将当前训练的**所有状态**（包括模型权重、优化器状态、当前是第几轮 epoch）保存到一个文件（例如 `latest_checkpoint.pth` 或 `model_epoch_10.pth`）。

2.  **安全停止**：
    当您按下 `Ctrl + C` 时，您丢失的**仅仅是**从上一个检查点（例如 epoch 10 结束时）到您按下 `Ctrl+C` 时（可能在 epoch 11 中途）这中间的少量进度。

3.  **恢复训练 (Resume)**：
    下次您想继续训练时，您可以重新运行训练脚本，并**指定**它从 `latest_checkpoint.pth` 这个文件**恢复**。脚本会读取这个文件，将模型权重、优化器和 epoch 轮数恢复到上次保存的状态（例如，它会自动从 epoch 11 开始训练），而不是从头开始。

-----

### 您需要做什么

1.  **检查您的训练脚本**：
    查看您用于启动训练的 `.py` 文件。它很可能会在训练过程中自动在某个文件夹（例如 `models/` 或 `checkpoints/`）创建 `.pth` 或 `.h5` 文件。

2.  **查找恢复参数**：
    查看该脚本的说明（例如您之前删除的那些 `.md` 文件，或者 `README_CN.md`），看看如何“恢复”(resume) 训练。通常会有一个像下面这样的参数：

    ```bash
    # 示例（您的脚本可能不同）
    python train.py --resume_from_checkpoint 'checkpoints/latest_model.pth'
    ```

**总结**：在按 `Ctrl + C` 之前，最好**等待当前的 epoch 训练完成**。这样，当检查点文件被保存后，您再停止它，下次就可以 100% 无缝地从下一轮 epoch 继续训练。