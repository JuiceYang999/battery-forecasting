# **数据分析和结果可视化**

### 准备工作：启动 Jupyter Notebook

1.  **打开一个新的 Anaconda Prompt 终端**。（保持你原来的终端继续运行任务）
2.  激活你的 Conda 环境：
    ```bash
    conda activate blackbody
    ```
3.  `cd` (切换目录) 进入你新创建的 `data_processing` 文件夹：
    ```bash
    # 示例路径，请修改为你自己的
    cd "d:\code9\battery-forecasting-main（跑代码）\data_processing\"
    ```
4.  启动 Jupyter Lab：
    ```bash
    jupyter lab
    ```
    这会在你的浏览器中打开一个新的 Jupyter Lab 界面。
5.  在 Jupyter Lab 中，新建一个 Notebook，可以命名为 `analysis.ipynb`。

-----

### 可视化操作一：复现 Figure 3a (核心性能)

**目标：** 可视化 `1next-cycle-capacity.py` 的交叉验证结果，绘制“预测容量” vs “实际容量”的散点图。

**数据来源：** `../results/variable-discharge/predictions/` 文件夹下所有 `eis-actions` 的 `.npy` 文件。

**在你的 `analysis.ipynb` Notebook 中输入以下代码：**

#### 步骤 1.1：导入库

```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import glob # 用于查找文件

# 设置 Matplotlib 样式
sns.set_theme(style="whitegrid")
print("库导入成功！")
```

#### 步骤 1.2：加载并合并数据

`1next-cycle-capacity.py` 脚本为12次拆分（splits）中的每一次都保存了单独的预测文件。我们需要把它们全部找出来并合并。

```python
# 定义数据路径
# (../ 指的是从 data_processing 返回到项目根目录)
pred_path = '../results/variable-discharge/predictions/'

# 查找所有相关的预测文件和真实值文件
pred_files = sorted(glob.glob(os.path.join(pred_path, ''pred_mn_eis-cvfs-ct-c-actions_n1_xgb_*.npy')))
true_files = sorted(glob.glob(os.path.join(pred_path, 'true_eis-cvfs-ct-c-actions_n1_xgb_')))

# 加载并合并数据
all_predictions = []
all_true_values = []

for p_file, t_file in zip(pred_files, true_files):
    all_predictions.append(np.load(p_file))
    all_true_values.append(np.load(t_file))

# 将列表合并成一个大的 Numpy 数组
predictions = np.hstack(all_predictions)
true_values = np.hstack(all_true_values)

# 计算绝对误差，用于图表着色（和论文 Figure 3a 一致）
abs_error = np.abs(predictions - true_values)

print(f"成功加载了 {len(pred_files)} 组交叉验证数据")
print(f"总数据点: {len(predictions)}")
```

#### 步骤 1.3：绘制 Figure 3a

```python
plt.figure(figsize=(10, 8))

# 绘制散点图
# c=abs_error: 用绝对误差来着色
# cmap='YlOrRd': 使用和论文一致的黄-橙-红配色
sc = plt.scatter(true_values, predictions, c=abs_error, cmap='YlOrRd', alpha=0.7, s=20)

# 绘制 y=x 对角线 (完美预测线)
max_val = max(true_values.max(), predictions.max())
min_val = min(true_values.min(), predictions.min())
plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2, label='y=x (完美预测)')

# 添加颜色条
cbar = plt.colorbar(sc)
cbar.set_label('Predicted Error / mAh (绝对误差)', fontsize=14)

# 设置标签和标题
plt.xlabel('Actual Capacity / mAh (实际容量)', fontsize=16)
plt.ylabel('Predicted Capacity / mAh (预测容量)', fontsize=16)
plt.title('复现 Figure 3a: 核心性能预测', fontsize=18)
plt.legend(fontsize=12)
plt.axis('equal') # 让x轴和y轴等比例
plt.xlim(min_val, max_val)
plt.ylim(min_val, max_val)
plt.grid(True)
plt.show()
```

-----

### 可视化操作二：复现 Figure 6b (鲁棒性)

**目标：** 可视化 `1fixed-discharge-predict.py` 的结果，展示模型在“固定放电”数据集上的泛化能力。

**数据来源：** `../results/fixed-discharge/predictions/` 文件夹。

**在你的 Notebook 中继续输入以下代码：**

#### 步骤 2.1：加载数据

这次的文件是固定的，不需要 `glob`。

```python
# 定义数据路径
data_path = '../results/fixed-discharge/predictions/'

# 加载数据
pred_robust = np.load(os.path.join(data_path, 'pred_mn_eis-actions.npy'))
true_robust = np.load(os.path.join(data_path, 'true_eis-actions.npy'))

# 计算绝对误差，用于着色
abs_error_robust = np.abs(pred_robust - true_robust)

print(f"成功加载了鲁棒性测试数据，数据点: {len(pred_robust)}")
```

#### 步骤 2.2：绘制 Figure 6b

```python
plt.figure(figsize=(10, 8))

# 绘制散点图
sc_robust = plt.scatter(true_robust, pred_robust, c=abs_error_robust, cmap='YlOrRd', alpha=0.7, s=20)

# 绘制 y=x 对角线
max_val = max(true_robust.max(), pred_robust.max())
min_val = min(true_robust.min(), pred_robust.min())
plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2, label='y=x (完美预测)')

# 添加颜色条
cbar_robust = plt.colorbar(sc_robust)
cbar_robust.set_label('Predicted Error / mAh (绝对误差)', fontsize=14)

# 设置标签和标题
plt.xlabel('Actual Capacity / mAh (实际容量)', fontsize=16)
plt.ylabel('Predicted Capacity / mAh (预测容量)', fontsize=16)
plt.title('复现 Figure 6b: 域迁移鲁棒性测试', fontsize=18)
plt.legend(fontsize=12)
plt.axis('equal')
plt.xlim(min_val, max_val)
plt.ylim(min_val, max_val)
plt.grid(True)
plt.show()
```

-----

当你执行完这些步骤，你就获得了汇报中两个最核心的可视化结果，完美地展示了你的复现成果！

### 关于中文显示问题：

#### 1.基础解决：

 设置 Matplotlib 支持中文的字体
#'SimHei' (黑体) 是 Windows 系统上非常常见的中文字体
 如果你用的是 Mac，可以改成 'PingFang SC'
 如果你用的是 Linux，可以改成 'Source Han Sans SC'
plt.rcParams['font.sans-serif'] = ['SimHei']
#解决更改字体后，负号 '-' 显示为方块的问题
plt.rcParams['axes.unicode_minus'] = False

2.可能是虚拟环境冲突？（不是），而且另一个可以正常运行：所以我猜测，可能是”# 设置 Matplotlib 样式

sns.set_theme(style="whitegrid")print("库导入成功！")“的原因（这是个模板之类的意思？所以可能乱码？）（是的）

---

---



**问题的原因：**
`sns.set_theme(style="whitegrid")` 这行代码会**重置并覆盖** Matplotlib 的所有默认设置（`rcParams`），包括我们之前辛苦设置好的 `font.sans-serif` 列表。它会把字体强制改回 Seaborn 默认的 `Arial`，这就是你一直看到 `Arial` 警告并且中文显示为方块的原因。

你的新测试代码能成功，就是因为它**只用了 Matplotlib**，没有被 Seaborn 覆盖。

-----

### 解决方案

我们有两种方法可以解决这个问题，**推荐使用方法 A**，因为它最简洁。

请**用下面这个代码块**替换掉你 `analysis.ipynb` 笔记本中的**第一个代码单元格**（步骤 1.1）：

-----

#### 方法 A：在 Seaborn 中直接指定字体（推荐）

```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import glob # 用于查找文件
import matplotlib

# --- [新代码] 解决中文显示问题 (Seaborn 正确版) ---

# 你的测试代码证明了 'SimHei' 字体是可用的。
# 我们在 set_theme() 中直接把它传进去
font_name_to_use = 'SimHei' 

# 1. 在调用 set_theme 时，直接指定 font 参数
# 这样 Seaborn 就会在加载 'whitegrid' 样式时，主动使用 'SimHei' 字体
sns.set_theme(style="whitegrid", font=font_name_to_use)

# 2. 解决更改字体后，负号 '-' 显示为方块的问题
plt.rcParams['axes.unicode_minus'] = False 
# --- [新代码] 结束 ---

print(f"库导入成功！中文显示已配置，Seaborn 正在使用: {font_name_to_use}")
```

-----

#### 方法 B：在 Seaborn 之后再覆盖字体（也能用）

```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import glob # 用于查找文件
import matplotlib

# --- [新代码] 解决中文显示问题 (覆盖版) ---

# 1. 先让 Seaborn 设置它的样式，这会把字体改回 'Arial'
sns.set_theme(style="whitegrid")

# 2. 然后，我们再强行把字体改回来
plt.rcParams['font.sans-serif'] = ['SimHei'] # 使用你测试成功的字体
plt.rcParams['axes.unicode_minus'] = False 
# --- [新代码] 结束 ---

print("库导入成功！中文显示已配置 (已覆盖 Seaborn 默认字体)。")
```

-----

---

太好了！任务四 (`1data-efficiency.py`) 运行完毕，这意味着你现在可以复现论文中的 **Figure 5** 了。

这个脚本不会生成 `.npy` 预测文件，而是将\*\*最终的统计结果（R² 和 Error）\*\*直接写入了日志文件 `log-n-cells.txt`。

我们的下一步是：

1.  **解析**这个 `.txt` 日志文件，提取出“电芯数量”、“Test R2”和“Test error”。
2.  **绘制**这两张图表（Error vs. Cells, R2 vs. Cells）。

请在你的 `analysis.ipynb` 笔记本中，继续添加以下单元格：

-----

### 步骤 3.1：解析数据效率日志 (log-n-cells.txt)

这个单元格会读取 `log-n-cells.txt` 文件，使用正则表达式提取出关键数据，并存入一个 Pandas DataFrame 中以便绘图。

```python
import re # 导入正则表达式库
import pandas as pd # 导入 Pandas 库

# (!!!) 确保这个路径是正确的 (!!!)
log_file_path = '../experiments/results/variable-discharge/log-n-cells.txt'

# 用于存放我们提取的数据
data_efficiency_results = []

# (!!!) [已修正] 这是你日志中的关键信息 (e.g., "Splits:2", "Splits:4")
# 我们用它来代表电芯数量
cell_regex = re.compile(r'Splits:(\d+)') 

# (!!!) [已修正] 这是你日志中对应的统计数据
# Train R2: ... Train error: ... Test R2: [我们要的] Test error: [我们要的]
stats_regex = re.compile(r'Test R2: ([\d.-]+)\s+ Test error: ([\d.-]+)')

current_cells = None

try:
    with open(log_file_path, 'r', encoding='utf-8') as f:
        for line in f:
            # 1. 查找 "Splits:X" 这一行
            cell_match = cell_regex.search(line)
            if cell_match:
                # 找到了，把 X 存为电芯数量
                current_cells = int(cell_match.group(1))
            
            # 2. 查找 "Test R2: Y Test error: Z" 这一行
            stats_match = stats_regex.search(line)
            if stats_match and current_cells is not None:
                # 找到了，把 Y 和 Z 和 X 存到一起
                data_efficiency_results.append({
                    'Number of cells': current_cells,
                    'Test R2': float(stats_match.group(1)),
                    'Test error (%)': float(stats_match.group(2))
                })
                # 重置 current_cells，防止重复记录
                current_cells = None

    # 将结果转换为 Pandas DataFrame
    df_efficiency = pd.DataFrame(data_efficiency_results)
    
    if df_efficiency.empty:
        print(f"!!! 错误：无法从 {log_file_path} 中解析出任何数据。")
        print("请检查日志文件内容和正则表达式是否匹配。")
    else:
        # 按 "Number of cells" 排序，确保绘图时 X 轴是递增的
        df_efficiency = df_efficiency.sort_values(by='Number of cells')
        
        print("成功解析 'log-n-cells.txt' 文件：")
        print(df_efficiency)

except FileNotFoundError:
    print(f"!!! 错误：找不到日志文件 {log_file_path}")
    print("请确认 '1data-efficiency.py' 脚本是否已成功运行。")
```

-----

### 步骤 3.2：绘制 Figure 5a 和 5b (数据效率图)

这个单元格会使用上一步中生成的 `df_efficiency` DataFrame 来绘制论文中的 Figure 5。

```python
if 'df_efficiency' in locals() and not df_efficiency.empty:
    # 创建一个 1 行 2 列的图表
    fig, axes = plt.subplots(1, 2, figsize=(18, 6))

    # --- 绘制 Figure 5a: 测试误差 vs 电芯数量 ---
    axes[0].plot(df_efficiency['Number of cells'], df_efficiency['Test error (%)'], 
                 marker='o', linestyle='--', color='red')
    axes[0].set_xlabel('训练电芯数量 (Number of cells)', fontsize=14)
    axes[0].set_ylabel('测试误差 (%) (Test error)', fontsize=14)
    axes[0].set_title('复现 Figure 5a: 数据效率 (误差)', fontsize=16)
    axes[0].grid(True)
    # 设置 X 轴刻度为我们实际拥有的数据点
    axes[0].set_xticks(df_efficiency['Number of cells']) 

    # --- 绘制 Figure 5b: R² vs 电芯数量 ---
    
    # (!!!) [已修正] 使用 LaTeX 字符串 R$^2$ 来显示 R²
    axes[1].plot(df_efficiency['Number of cells'], df_efficiency['Test R2'], 
                 marker='o', linestyle='--', color='blue')
    axes[1].set_xlabel('训练电芯数量 (Number of cells)', fontsize=14)
    axes[1].set_ylabel('R$^2$ 值 (R² Value)', fontsize=14) # <--- 看这里！
    axes[1].set_title('复现 Figure 5b: 数据效率 (R$^2$)', fontsize=16)
    
    axes[1].grid(True)
    # 设置 X 轴刻度
    axes[1].set_xticks(df_efficiency['Number of cells'])
    # 设置 Y 轴范围，使其更接近论文样式
    axes[1].set_ylim(-0.2, 1.0) 

    # 自动调整布局
    plt.tight_layout()
    plt.show()
else:
    print("错误：'df_efficiency' DataFrame 不存在或为空。请先成功运行上一个单元格。")
```
太棒了！你已经跑完了所有核心的 `variable-discharge` 实验。

任务五 (`1n-step-lookahead.py`) 的结果保存在 `log-n-step-lookahead.txt` 文件中，它对应的是论文中的 **Figure 4**，展示了模型预测未来N个周期的能力。

和任务四一样，我们首先需要解析这个 `.txt` 日志文件，然后绘制图表。

请在你的 `analysis.ipynb` 笔记本中，继续添加以下单元格：

-----

### 步骤 4.1：解析N步预测日志 (log-n-step-lookahead.txt)

这个单元格会读取 `log-n-step-lookahead.txt`，提取出“预测步长 (n\_step)”、“Test R2”和“Test error”。

```python
import re # 导入正则表达式库
import pandas as pd # 导入 Pandas 库

# (!!!) 确保这个路径是正确的 (!!!)
log_file_path = '../results/variable-discharge/log-n-step-lookahead.txt'

# 用于存放我们提取的数据
n_step_results = []

# 定义正则表达式
# 匹配 "Output: Q_n+X"
step_regex = re.compile(r'Output: Q_n\+(\d+)') 

# 匹配 "Test R2: Y   Test error: Z"
# (我们沿用上次成功的、带空格的正则表达式)
stats_regex = re.compile(r'Test R2: ([\d.-]+)\s+ Test error: ([\d.-]+)')

current_step = None

try:
    with open(log_file_path, 'r', encoding='utf-8') as f:
        for line in f:
            # 1. 查找 "Output: Q_n+X" 这一行
            step_match = step_regex.search(line)
            if step_match:
                # 找到了，把 X 存为步长
                current_step = int(step_match.group(1))
            
            # 2. 查找 "Test R2: Y Test error: Z" 这一行
            stats_match = stats_regex.search(line)
            if stats_match and current_step is not None:
                # 找到了，把 Y 和 Z 和 X 存到一起
                n_step_results.append({
                    'n_step': current_step,
                    'Test R2': float(stats_match.group(1)),
                    'Test error (%)': float(stats_match.group(2))
                })
                # 重置 current_step，防止重复记录
                current_step = None

    # 将结果转换为 Pandas DataFrame
    df_n_step = pd.DataFrame(n_step_results)
    
    if df_n_step.empty:
        print(f"!!! 错误：无法从 {log_file_path} 中解析出任何数据。")
        print("请检查日志文件内容和正则表达式是否匹配。")
    else:
        # 按 "n_step" 排序，确保绘图时 X 轴是递增的
        df_n_step = df_n_step.sort_values(by='n_step')
        
        print("成功解析 'log-n-step-lookahead.txt' 文件：")
        print(df_n_step)

except FileNotFoundError:
    print(f"!!! 错误：找不到日志文件 {log_file_path}")
    print("请确认 '1n-step-lookahead.py' 脚本是否已成功运行。")
```

-----

### 步骤 4.2：绘制 Figure 4a 和 4b (N步预测图)

这个单元格会使用上一步中生成的 `df_n_step` DataFrame 来绘制论文中的 Figure 4。

```python
if 'df_n_step' in locals() and not df_n_step.empty:
    # 创建一个 1 行 2 列的图表
    fig, axes = plt.subplots(1, 2, figsize=(18, 6))

    # --- 绘制 Figure 4a: 测试误差 vs 预测步长 ---
    axes[0].plot(df_n_step['n_step'], df_n_step['Test error (%)'], 
                 marker='o', linestyle='--', color='red')
    axes[0].set_xlabel('预测未来周期数 (Number of cycles)', fontsize=14)
    axes[0].set_ylabel('测试误差 (%) (Test error)', fontsize=14)
    axes[0].set_title('复现 Figure 4a: 长期预测 (误差)', fontsize=16)
    axes[0].grid(True)
    # 设置 X 轴刻度为我们实际拥有的数据点
    axes[0].set_xticks(df_n_step['n_step']) 
    # 调整X轴标签角度，防止重叠
    axes[0].tick_params(axis='x', rotation=45)

    # --- 绘制 Figure 4b: R² vs 预测步长 ---
    axes[1].plot(df_n_step['n_step'], df_n_step['Test R2'], 
                 marker='o', linestyle='--', color='blue')
    axes[1].set_xlabel('预测未来周期数 (Number of cycles)', fontsize=14)
    # 使用 LaTeX 字符串 R$^2$ 来显示 R²
    axes[1].set_ylabel('R$^2$ 值 (R² Value)', fontsize=14)
    axes[1].set_title('复现 Figure 4b: 长期预测 (R²)', fontsize=16)
    axes[1].grid(True)
    # 设置 X 轴刻度
    axes[1].set_xticks(df_n_step['n_step'])
    # 设置 Y 轴范围，使其更接近论文样式
    axes[1].set_ylim(0.6, 0.9) # 论文中的 Y 轴范围是 0.6 到 0.9
    axes[1].tick_params(axis='x', rotation=45)

    # 自动调整布局
    plt.tight_layout()
    plt.show()
else:
    print("错误：'df_n_step' DataFrame 不存在或为空。请先成功运行上一个单元格。")
```
非常棒！你已经完成了 `variable-discharge-type2`（第二批电芯）相关的实验。

你说的“任务六” (`2vd2-train.py`) 主要是用来训练模型的。而真正生成分析结果的，是**任务 7** (`2next-cycle-capacity-vd2.py`) 和**任务 8** (`2vd2-predict.py`)。

  * **任务 7** 的结果对应论文中的 **Table 2**（验证模型对不同制造商和不同使用模式的鲁棒性）。
  * 此处任务七模型数量太多，训练速度太慢：已经训练的两个：
* 成功解析 'log-next-cycle-random-split-32.txt' (任务 7) 文件：
      Feature Set   Test R2  Test error (%)
  1  cvfs-actions  0.647736       16.879349
  0       actions  0.311024       22.756776
* ![image-20251110090232034](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20251110090232034.png)
* 参数替换：
      'max_depth': 10,       # [修改] 100 -> 10 (极大降低单个模型的复杂度)
      'n_splits': 4,         # [修改] 16 -> 4 (极大减少总循环次数)
      'n_estimators': 25,    # [修改] 50 -> 25 (减少树的数量)
      'n_ensembles': 2       # [修改] 10 -> 2 (极大减少集成模型的数量)
  * **任务 8** 的结果对应论文中的 **Table 3**（验证模型对**不同温度**的鲁棒性）。

我们将把这两部分的分析都添加到你的 `analysis.ipynb` 笔记本中。

-----

### 步骤 5.1：解析任务 7 日志 (log-next-cycle-random-split-32.txt)

这个单元格会解析任务 7 的日志文件，提取出不同特征组合（如 'eis-actions' vs 'cvfs-actions'）的性能，以便复现 Table 2。

```python
import re # 导入正则表达式库
import pandas as pd # 导入 Pandas 库

# (!!!) 确保这个路径是正确的 (!!!)
log_file_path = '../results/variable-discharge-type2/log-next-cycle-random-split-32.txt'

# 用于存放我们提取的数据
vd2_results = []

# 定义正则表达式
# 匹配 "Input: X"
input_regex = re.compile(r'Input: ([\w-]+)') 

# 匹配 "Test R2: Y   Test error: Z"
# (我们沿用之前成功的正则表达式)
stats_regex = re.compile(r'Test R2: ([\d.-]+)\s+ Test error: ([\d.-]+)')

current_input = None

try:
    with open(log_file_path, 'r', encoding='utf-8') as f:
        for line in f:
            # 1. 查找 "Input: X" 这一行
            input_match = input_regex.search(line)
            if input_match:
                # 找到了，把 X 存为特征名称
                current_input = input_match.group(1)
            
            # 2. 查找 "Test R2: Y Test error: Z" 这一行
            stats_match = stats_regex.search(line)
            if stats_match and current_input is not None:
                # 找到了，把 Y 和 Z 和 X 存到一起
                vd2_results.append({
                    'Feature Set': current_input,
                    'Test R2': float(stats_match.group(1)),
                    'Test error (%)': float(stats_match.group(2))
                })
                # 重置 current_input，防止重复记录
                current_input = None

    # 将结果转换为 Pandas DataFrame
    df_vd2 = pd.DataFrame(vd2_results)
    
    if df_vd2.empty:
        print(f"!!! 错误：无法从 {log_file_path} 中解析出任何数据。")
        print("请检查日志文件内容和正则表达式是否匹配。")
    else:
        # 按 "Test error (%)" 排序，看看哪个特征最好
        df_vd2 = df_vd2.sort_values(by='Test error (%)')
        
        print("成功解析 'log-next-cycle-random-split-32.txt' (任务 7) 文件：")
        print(df_vd2)

except FileNotFoundError:
    print(f"!!! 错误：找不到日志文件 {log_file_path}")
    print("请确认 '2next-cycle-capacity-vd2.py' (任务 7) 脚本是否已成功运行。")
```

-----

### 步骤 5.2：绘制 Table 2 (制造商/使用模式鲁棒性)

这个单元格会把 `df_vd2` 的数据用条形图（Bar Chart）展示出来，直观地对比不同特征组合的性能。

```python
if 'df_vd2' in locals() and not df_vd2.empty:
    # 创建一个 1 行 2 列的图表
    fig, axes = plt.subplots(1, 2, figsize=(20, 7))

    # --- 绘制 图 5.2a: 测试误差 (%) ---
    sns.barplot(x='Test error (%)', y='Feature Set', data=df_vd2, ax=axes[0], palette='Reds')
    axes[0].set_xlabel('测试误差 (%) (Test error)', fontsize=14)
    axes[0].set_ylabel('特征组合 (Feature Set)', fontsize=14)
    axes[0].set_title('复现 Table 2: 制造商/使用模式鲁棒性 (误差)', fontsize=16)
    axes[0].grid(True)

    # --- 绘制 图 5.2b: R² 值 ---
    # 按 R2 降序排列
    df_vd2_r2_sorted = df_vd2.sort_values(by='Test R2', ascending=False)
    sns.barplot(x='Test R2', y='Feature Set', data=df_vd2_r2_sorted, ax=axes[1], palette='Blues')
    axes[1].set_xlabel('R$^2$ 值 (R² Value)', fontsize=14)
    axes[1].set_ylabel('特征组合 (Feature Set)', fontsize=14)
    axes[1].set_title('复现 Table 2: 制造商/使用模式鲁棒性 (R²)', fontsize=16)
    axes[1].set_xlim(0, 1.0) # R2 范围从 0 到 1
    axes[1].grid(True)

    # 自动调整布局
    plt.tight_layout()
    plt.show()
else:
    print("错误：'df_vd2' DataFrame 不存在或为空。请先成功运行上一个单元格。")
```

-----

### 步骤 6.1：加载任务 8 数据 (温度鲁棒性)

这个单元格会加载任务 8 (`2vd2-predict.py`) 生成的 `.npy` 文件。**这个实验是将在 23°C 数据上训练的模型，用于预测 35°C 的数据**，对应论文 Table 3。

```python
from sklearn.metrics import r2_score # 导入 R2 评估工具

# (!!!) 确保这个路径是正确的 (!!!)
# 这是 '2vd2-predict.py' 脚本中定义的 'exp_test'
data_path = '../results/vd2-35C/predictions/'

# '2vd2-predict.py' 脚本中硬编码了 input_name = 'eis-actions'
input_name = 'eis-actions'

# 定义文件名
pred_file = os.path.join(data_path, f'vd1_pred_mn_{input_name}.npy')
true_file = os.path.join(data_path, f'vd1_true_{input_name}.npy')

try:
    # 加载数据
    pred_temp = np.load(pred_file)
    true_temp = np.load(true_file)
    
    # 计算误差
    abs_error_temp = np.abs(pred_temp - true_temp)
    
    # 计算 R2 和 % Error
    r2_temp = r2_score(true_temp, pred_temp)
    percent_error_temp = np.median(abs_error_temp / true_temp) * 100
    
    print(f"成功加载了 {input_name} (任务 8) 数据，数据点: {len(pred_temp)}")
    print(f"--- 23°C -> 35°C 温度鲁棒性测试结果 (复现 Table 3) ---")
    print(f"    Test R2: {r2_temp:.4f}")
    print(f"    Test error: {percent_error_temp:.2f}%")

except FileNotFoundError:
    print(f"!!! 错误：找不到 .npy 文件 {pred_file} 或 {true_file}")
    print("请确认 '2vd2-predict.py' (任务 8) 脚本是否已成功运行。")
```

-----

### 步骤 6.2：绘制 Figure Table 3 (温度鲁棒性散点图)

最后，我们把这个温度测试的结果也画成散点图。

```python
if 'pred_temp' in locals():
    plt.figure(figsize=(10, 8))

    # 绘制散点图
    sc_temp = plt.scatter(true_temp, pred_temp, c=abs_error_temp, cmap='coolwarm', alpha=0.7, s=20)

    # 绘制 y=x 对角线
    all_data_temp = np.concatenate([true_temp, pred_temp])
    min_val_temp = np.min(all_data_temp)
    max_val_temp = np.max(all_data_temp)
    plt.plot([min_val_temp, max_val_temp], [min_val_temp, max_val_temp], 'k--', lw=2, label='y=x (完美预测)')

    # 添加颜色条
    cbar_temp = plt.colorbar(sc_temp)
    cbar_temp.set_label('Predicted Error / mAh (绝对误差)', fontsize=14)

    # 设置标签和标题
    plt.xlabel('Actual Capacity / mAh (实际容量 - 35°C)', fontsize=16)
    plt.ylabel('Predicted Capacity / mAh (预测容量 - 23°C 模型)', fontsize=16)
    plt.title('复现 Table 3: 温度鲁棒性测试 (23°C -> 35°C)', fontsize=18)
    plt.legend(fontsize=12)

    # 自动调整坐标轴（因为我们删除了 plt.axis('equal')）
    plt.grid(True)
    plt.show()
else:
    print("错误：'pred_temp' 数据不存在。请先成功运行上一个单元格。")
```
你观察得非常仔细！你说得对，我们的 `run_all_experiments.py` 脚本生成了海量的 `.npy` 文件和 `.pkl` 模型文件，而我们目前主要分析的是 `.txt` 日志文件和少数几个关键的 `.npy` 预测文件。

你所说的“没有用上的数据”主要分为两类：

1.  **模型文件 (`.pkl`)**：

      * **位置**: `results/variable-discharge/models/` 和 `results/variable-discharge-type2/models/`
      * **用途**: 这些是 `xgboost` 训练好的模型。它们不是“结果”，而是生成“结果”（`.npy` 预测文件）的**工具**。
      * **分析**: 我们**不需要**对它们进行可视化。它们的存在证明了任务1和任务6已经成功运行。

2.  **详细的预测文件 (`.npy`)**：

      * **位置**: `results/variable-discharge/predictions/`, `results/variable-discharge-type2/predictions/` 等。
      * **用途**: 这些是每个交叉验证拆分（cross-validation split）中，每个特征组合（feature set）对每个测试电芯（test cell）的具体预测值。
      * **分析**: 我们**已经**分析了这里面最重要的部分！
          * `Fig 3a`（核心性能）就是分析了 `variable-discharge/predictions/` 里的 `eis-cvfs-ct-c-actions...` 文件。
          * `Fig 6b`（鲁棒性）就是分析了 `fixed-discharge/predictions/` 里的文件。
          * `Table 3`（温度鲁棒性）就是分析了 `vd2-35C/predictions/` 里的文件。

-----

### 尚未可视化的“有用数据”

你说的没错，还有一个数据我们**只分析了日志，但没有画成散点图**：

  * **任务 7** (`2next-cycle-capacity-vd2.py`) 的结果。

我们之前在 **步骤 5.2** 中，通过分析日志 `log-next-cycle-random-split-32.txt` 绘制了条形图（Bar Chart）来复现 **Table 2**。

现在，我们可以通过加载 `results/variable-discharge-type2/predictions/` 文件夹中的 `.npy` 文件，来绘制一个**散点图**，作为 Table 2 的**可视化证据**。

-----

请在你的 `analysis.ipynb` 笔记本中，继续添加以下单元格：

### 步骤 7.1：加载任务 7 (Type 2 电芯) 的预测数据

这个单元格会加载 `variable-discharge-type2` 实验的 `.npy` 预测文件。我们将选用 `eis-actions` 这个特征组合，因为它是在 Table 2 中与 Table 1 (`eis-actions`) 进行对比的基础特征。

```python
import numpy as np
import os
import glob
from sklearn.metrics import r2_score, mean_squared_error

# (!!!) 确保这个路径是正确的 (!!!)
pred_path_vd2 = '../results/variable-discharge-type2/predictions/'

# (!!!) [关键] 检查文件名 (!!!)
# '2next-cycle-capacity-vd2.py' 生成的 .npy 文件
# 实验名称为 '{}_n1_xgb2'.format(input_name)
glob_pattern_pred = 'pred_mn_eis-actions_n1_xgb2_*.npy'
glob_pattern_true = 'true_eis-actions_n1_xgb2_*.npy'

# 查找所有相关的预测文件和真实值文件
pred_files_vd2 = sorted(glob.glob(os.path.join(pred_path_vd2, glob_pattern_pred)))
true_files_vd2 = sorted(glob.glob(os.path.join(pred_path_vd2, glob_pattern_true)))

try:
    if not pred_files_vd2:
        print(f"!!! 错误：在 {pred_path_vd2} 中没有找到 '{glob_pattern_pred}' 文件")
        print("请确认 '2next-cycle-capacity-vd2.py' (任务 7) 脚本是否已成功运行。")
    else:
        # 加载并合并数据
        all_predictions_vd2 = []
        all_true_values_vd2 = []

        for p_file, t_file in zip(pred_files_vd2, true_files_vd2):
            all_predictions_vd2.append(np.load(p_file))
            all_true_values_vd2.append(np.load(t_file))

        # 将列表合并成一个大的 Numpy 数组
        pred_vd2 = np.hstack(all_predictions_vd2)
        true_vd2 = np.hstack(all_true_values_vd2)

        # 计算绝对误差，用于图表着色
        abs_error_vd2 = np.abs(pred_vd2 - true_vd2)
        
        # 计算 R2 和 % Error (与 Table 2 日志进行核对)
        r2_vd2 = r2_score(true_vd2, pred_vd2)
        percent_error_vd2 = np.median(abs_error_vd2 / true_vd2) * 100

        print(f"成功加载了 {len(pred_files_vd2)} 组 'eis-actions' (任务 7) 交叉验证数据")
        print(f"总数据点: {len(pred_vd2)}")
        print(f"--- 'eis-actions' (Type 2 电芯) 性能指标 ---")
        print(f"    Test R2 (计算值): {r2_vd2:.4f}")
        print(f"    Test error (计算值): {percent_error_vd2:.2f}%")
        print("(你可以将此结果与 步骤 5.2 中 'eis-actions' 的条形图结果进行核对)")

except Exception as e:
    print(f"加载数据时出错: {e}")
```

### 步骤 7.2：绘制 Table 2 (Type 2 电芯) 的散点图

这个单元格会把 `pred_vd2` 和 `true_vd2` 绘制成散点图，为 Table 2 提供直观的可视化。

```python
if 'pred_vd2' in locals():
    plt.figure(figsize=(10, 8))

    # 绘制散点图
    sc_vd2 = plt.scatter(true_vd2, pred_vd2, c=abs_error_vd2, cmap='viridis', alpha=0.7, s=20)

    # 绘制 y=x 对角线
    all_data_vd2 = np.concatenate([true_vd2, pred_vd2])
    min_val_vd2 = np.min(all_data_vd2)
    max_val_vd2 = np.max(all_data_vd2)
    plt.plot([min_val_vd2, max_val_vd2], [min_val_vd2, max_val_vd2], 'k--', lw=2, label='y=x (完美预测)')

    # 添加颜色条
    cbar_vd2 = plt.colorbar(sc_vd2)
    cbar_vd2.set_label('Predicted Error / mAh (绝对误差)', fontsize=14)

    # 设置标签和标题
    plt.xlabel('Actual Capacity / mAh (实际容量 - Type 2 电芯)', fontsize=16)
    plt.ylabel('Predicted Capacity / mAh (预测容量 - Type 2 模型)', fontsize=16)
    plt.title('复现 Table 2: Type 2 电芯性能 (eis-actions)', fontsize=18)
    plt.legend(fontsize=12)

    # 自动调整坐标轴
    plt.grid(True)
    plt.show()
else:
    print("错误：'pred_vd2' 数据不存在。请先成功运行上一个单元格。")
```
你真是火眼金睛，观察得太仔细了！

你完全正确，我们跳过了 `log-next-cycle-12s.txt` 这个文件。我之前的疏忽是：

  * 在**步骤 1** (`Figure 3a`) 中，我们直接分析了 `.npy` 文件，而没有分析生成它的日志。
  * 在**步骤 5** (`Table 2`) 中，我们分析了 `variable-discharge-type2` 的日志。

我们**尚未**分析 `variable-discharge`（Type 1 电芯）的**核心对比日志**。

你指出的 `log-next-cycle-12s.txt` 文件，正是由**任务 3** (`1next-cycle-capacity.py`) 生成的，它对应的是论文中**最重要**的 **Table 1** —— 即不同特征组合（Feature Set）的性能对比。

让我们现在就来分析它！

-----

请在你的 `analysis.ipynb` 笔记本中，继续添加以下单元格：

### 步骤 8.1：解析核心性能日志 (log-next-cycle-12s.txt)

这个单元格会解析任务 3 的日志文件，提取出你脚本中三种特征组合（`ecmr-cvfs-ct-c-actions`, `ecmer-cvfs-ct-c-actions`, `eis-cvfs-ct-c-actions`）的性能，以便复现 Table 1 的最后三行。

```python
import re # 导入正则表达式库
import pandas as pd # 导入 Pandas 库

# (!!!) 确保这个路径是正确的 (!!!)
log_file_path = '../results/variable-discharge/log-next-cycle-12s.txt'

# 用于存放我们提取的数据
core_results = []

# 定义正则表达式
# 匹配 "Input: X"
input_regex = re.compile(r'Input: ([\w-]+)') 

# 匹配 "Test R2: Y   Test error: Z"
# (我们沿用之前成功的正则表达式)
stats_regex = re.compile(r'Test R2: ([\d.-]+)\s+ Test error: ([\d.-]+)')

current_input = None

try:
    with open(log_file_path, 'r', encoding='utf-8') as f:
        for line in f:
            # 1. 查找 "Input: X" 这一行
            input_match = input_regex.search(line)
            if input_match:
                # 找到了，把 X 存为特征名称
                current_input = input_match.group(1)
            
            # 2. 查找 "Test R2: Y Test error: Z" 这一行
            stats_match = stats_regex.search(line)
            if stats_match and current_input is not None:
                # 找到了，把 Y 和 Z 和 X 存到一起
                core_results.append({
                    'Feature Set': current_input,
                    'Test R2': float(stats_match.group(1)),
                    'Test error (%)': float(stats_match.group(2))
                })
                # 重置 current_input，防止重复记录
                current_input = None

    # 将结果转换为 Pandas DataFrame
    df_core = pd.DataFrame(core_results)
    
    if df_core.empty:
        print(f"!!! 错误：无法从 {log_file_path} 中解析出任何数据。")
        print("请检查日志文件内容和正则表达式是否匹配。")
    else:
        # 按 "Test error (%)" 排序，看看哪个特征最好
        df_core = df_core.sort_values(by='Test error (%)')
        
        print("成功解析 'log-next-cycle-12s.txt' (任务 3) 文件：")
        print(df_core)

except FileNotFoundError:
    print(f"!!! 错误：找不到日志文件 {log_file_path}")
    print("请确认 '1next-cycle-capacity.py' (任务 3) 脚本是否已成功运行。")
```

-----

### 步骤 8.2：绘制 Table 1 (核心性能对比)

这个单元格会把 `df_core` 的数据用条形图（Bar Chart）展示出来，直观地对比这三种高级特征组合的性能。

```python
if 'df_core' in locals() and not df_core.empty:
    # 创建一个 1 行 2 列的图表
    fig, axes = plt.subplots(1, 2, figsize=(20, 7))

    # --- 绘制 图 8.2a: 测试误差 (%) ---
    sns.barplot(x='Test error (%)', y='Feature Set', data=df_core, ax=axes[0], palette='Reds')
    axes[0].set_xlabel('测试误差 (%) (Test error)', fontsize=14)
    axes[0].set_ylabel('特征组合 (Feature Set)', fontsize=14)
    axes[0].set_title('复现 Table 1: 核心特征性能对比 (误差)', fontsize=16)
    axes[0].grid(True)

    # --- 绘制 图 8.2b: R² 值 ---
    # 按 R2 降序排列
    df_core_r2_sorted = df_core.sort_values(by='Test R2', ascending=False)
    sns.barplot(x='Test R2', y='Feature Set', data=df_core_r2_sorted, ax=axes[1], palette='Blues')
    axes[1].set_xlabel('R$^2$ 值 (R² Value)', fontsize=14)
    axes[1].set_ylabel('特征组合 (Feature Set)', fontsize=14)
    axes[1].set_title('复现 Table 1: 核心特征性能对比 (R²)', fontsize=16)
    axes[1].set_xlim(0, 1.0) # R2 范围从 0 到 1
    axes[1].grid(True)

    # 自动调整布局
    plt.tight_layout()
    plt.show()
else:
    print("错误：'df_core' DataFrame 不存在或为空。请先成功运行上一个单元格。")
```

-----

### **重要说明：如何*真正*复现 Table 1**

当你运行上面的代码时，你会看到一个**只有 3 根柱子**的条形图。

这是因为你的 `1next-cycle-capacity.py` 脚本中的 `input_names` 列表**只包含了 3 个特征集**：
`['ecmr-cvfs-ct-c-actions', 'ecmer-cvfs-ct-c-actions', 'eis-cvfs-ct-c-actions']`

如果你想**完整复现**论文中的 Table 1，你**必须**：

1.  打开 `experiments/1next-cycle-capacity.py`。
2.  修改 `input_names` 列表，把 Table 1 中的**所有**特征集都加进去。根据 `utils/exp_util.py` 的定义，它们的名字是：
    ```python
    input_names = [
        'actions',              # 对应 "Protocol only"
        'eis',                  # 对应 "EIS only"
        'eis-actions',          # 对应 "EIS + Protocol"
        'ecmr-actions',         # 对应 "ECM-R + Protocol"
        'ecmer-actions',        # 对应 "ECM-ER + Protocol"
        'soh-actions',          # 对应 "SOH + Protocol" (近似)
        'cvfs-actions',         # 对应 "CVF + Protocol"
        'ct-actions',           # 对应 "CT + Protocol" (近似)
        'c-actions',            # 对应 "Qn-1 + Protocol" (近似)
        'eis-cvfs-actions',     # 对应 "EIS + CVF + Protocol"
        'eis-cvfs-ct-c-actions' # 对应 "EIS + CVF + CT+Q-1+ Protocol"
    ]
    ```
3.  **重新运行** `1next-cycle-capacity.py` 脚本（或 `run_all_experiments.py` 的任务 3）。
4.  运行完毕后，再回到 `analysis.ipynb` 重新运行**步骤 8.1 和 8.2**，你就会得到一个包含 11 根柱子的、完整的 Table 1 复现图表。